#!/bin/bash

# Copyright (c) Meta Platforms, Inc. and affiliates.
# All rights reserved.
#
# This source code is licensed under the BSD-style license found in the
# LICENSE file in the root directory of this source tree.

# Run this script to update the resources used in unit tests. The resources are all derived
# from source media already checked into the repo.

# Fail loudly on errors.
set -x
set -e

TORCHCODEC_PATH=$HOME/fbsource/fbcode/pytorch/torchcodec
RESOURCES_DIR=$TORCHCODEC_PATH/test/resources
VIDEO_PATH=$RESOURCES_DIR/nasa_13013.mp4

# Last generated with ffmpeg version 4.3
#
# Note: The naming scheme used here must match the naming scheme used to load
# tensors in ./utils.py.
FRAMES=(0 1 2 3 4 5 6 7 8 9)
FRAMES+=(15 20 25 30 35)
FRAMES+=(386 387 388 389)
for frame in "${FRAMES[@]}"; do
  # Note that we are using 0-based index naming. Asking ffmpeg to number output
  # frames would result in 1-based index naming. We enforce 0-based index naming
  # so that the name of reference frames matches the index when accessing that
  # frame in the Python decoder.
  frame_name=$(printf "%06d" "$frame")
  ffmpeg -y -i "$VIDEO_PATH" -vf select="eq(n\,$frame)" -vsync vfr -q:v 2 "$VIDEO_PATH.frame$frame_name.bmp"
done
ffmpeg -y -ss 6.0 -i "$VIDEO_PATH" -frames:v 1 "$VIDEO_PATH.time6.000000.bmp"
ffmpeg -y -ss 6.1 -i "$VIDEO_PATH" -frames:v 1 "$VIDEO_PATH.time6.100000.bmp"
ffmpeg -y -ss 10.0 -i "$VIDEO_PATH" -frames:v 1 "$VIDEO_PATH.time10.000000.bmp"
# This is the last frame of this video.
ffmpeg -y -ss 12.979633 -i "$VIDEO_PATH" -frames:v 1 "$VIDEO_PATH.time12.979633.bmp"
# Audio generation in the form of an mp3.
ffmpeg -y -i "$VIDEO_PATH" -b:a 192K -vn "$VIDEO_PATH.audio.mp3"

# TODO: Add frames decoded by Nvidia's NVDEC.

# This video was generated by running the following:
# conda install -c conda-forge x265
# ./configure --enable-nonfree --enable-gpl --prefix=$(readlink -f ../bin) --enable-libx265  --enable-rpath --extra-ldflags=-Wl,-rpath=$CONDA_PREFIX/lib --enable-filter=drawtext --enable-libfontconfig --enable-libfreetype --enable-libharfbuzz
# ffmpeg -f lavfi -i color=size=128x128:duration=1:rate=10:color=blue -vf "drawtext=fontsize=30:fontcolor=white:x=(w-text_w)/2:y=(h-text_h)/2:text='Frame %{frame_num}'" -vcodec libx265 -pix_fmt yuv420p -g 2 -crf 10 h265_video.mp4 -y
VIDEO_PATH=$RESOURCES_DIR/h265_video.mp4
FRAMES=(6)
for frame in "${FRAMES[@]}"; do
  frame_name=$(printf "%06d" "$frame")
  ffmpeg -y -i "$VIDEO_PATH" -vf select="eq(n\,$frame)" -vsync vfr -q:v 2 "$VIDEO_PATH.frame$frame_name.bmp"
done

for bmp in "$RESOURCES_DIR"/*.bmp
do
  python3 "$TORCHCODEC_PATH/test/convert_image_to_tensor.py" "$bmp"
  rm -f "$bmp"
done
