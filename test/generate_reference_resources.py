#!/usr/bin/env python3
import os
import subprocess

import numpy as np

import torch
from PIL import Image

# Copyright (c) Meta Platforms, Inc. and affiliates.
# All rights reserved.
#
# This source code is licensed under the BSD-style license found in the
# LICENSE file in the root directory of this source tree.

# Run this script to update the resources used in unit tests. The resources are all derived
# from source media already checked into the repo.


def convert_image_to_tensor(image_path):
    if not os.path.exists(image_path):
        return
    # Get base filename without extension
    base_filename = os.path.splitext(image_path)[0]
    pil_image = Image.open(image_path)
    img_tensor = torch.from_numpy(np.asarray(pil_image))
    print(img_tensor.shape)
    print(img_tensor.dtype)
    # Save tensor to disk
    torch.save(img_tensor, base_filename + ".pt", _use_new_zipfile_serialization=True)
    os.remove(image_path)


def main():
    SCRIPT_DIR = os.path.dirname(os.path.abspath(__file__))
    TORCHCODEC_PATH = os.path.dirname(SCRIPT_DIR)
    RESOURCES_DIR = os.path.join(TORCHCODEC_PATH, "test", "resources")
    VIDEO_PATH = os.path.join(RESOURCES_DIR, "nasa_13013.mp4")

    # Last generated with ffmpeg version 4.3
    #
    # Note: The naming scheme used here must match the naming scheme used to load
    # tensors in ./utils.py.
    STREAMS = [0, 3]
    FRAMES = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 15, 20, 25, 30, 35, 386, 387, 388, 389]
    for stream in STREAMS:
        for frame in FRAMES:
            # Note that we are using 0-based index naming. Asking ffmpeg to number output
            # frames would result in 1-based index naming. We enforce 0-based index naming
            # so that the name of reference frames matches the index when accessing that
            # frame in the Python decoder.
            output_bmp = f"{VIDEO_PATH}.stream{stream}.frame{frame:06d}.bmp"
            frame_name = f"{frame:06d}"
            cmd = [
                "ffmpeg",
                "-y",
                "-i",
                VIDEO_PATH,
                "-map",
                f"0:{stream}",
                "-vf",
                f"select=eq(n\\,{frame})",
                "-vsync",
                "vfr",
                "-q:v",
                "2",
                output_bmp,
            ]
            subprocess.run(cmd, check=True)
            convert_image_to_tensor(output_bmp)

    # Extract individual frames at specific timestamps, including the last frame of the video.
    seek_timestamp = [6.0, 6.1, 10.0, 12.979633]
    timestamp_name = [f"{seek_timestamp:06f}" for seek_timestamp in seek_timestamp]
    for timestamp, name in zip(seek_timestamp, timestamp_name):
        output_bmp = f"{VIDEO_PATH}.time{name}.bmp"
        cmd = [
            "ffmpeg",
            "-y",
            "-ss",
            str(timestamp),
            "-i",
            VIDEO_PATH,
            "-frames:v",
            "1",
            f"{VIDEO_PATH}.time{name}.bmp",
        ]
        subprocess.run(cmd, check=True)
        convert_image_to_tensor(output_bmp)

    # This video was generated by running the following:
    # conda install -c conda-forge x265
    # ./configure --enable-nonfree --enable-gpl --prefix=$(readlink -f ../bin) --enable-libx265  --enable-rpath --extra-ldflags=-Wl,-rpath=$CONDA_PREFIX/lib --enable-filter=drawtext --enable-libfontconfig --enable-libfreetype --enable-libharfbuzz
    # ffmpeg -f lavfi -i color=size=128x128:duration=1:rate=10:color=blue -vf "drawtext=fontsize=30:fontcolor=white:x=(w-text_w)/2:y=(h-text_h)/2:text='Frame %{frame_num}'" -vcodec libx265 -pix_fmt yuv420p -g 2 -crf 10 h265_video.mp4 -y
    # Note that this video only has 1 stream, at index 0.
    VIDEO_PATH = os.path.join(RESOURCES_DIR, "h265_video.mp4")
    FRAMES = [5]
    for frame in FRAMES:
        frame_name = f"{frame:06d}"
        output_bmp = f"{VIDEO_PATH}.stream0.frame{frame_name}.bmp"
        cmd = [
            "ffmpeg",
            "-y",
            "-i",
            VIDEO_PATH,
            "-vf",
            f"select=eq(n\\,{frame})",
            "-vsync",
            "vfr",
            "-q:v",
            "2",
            output_bmp,
        ]
        subprocess.run(cmd, check=True)
        convert_image_to_tensor(output_bmp)

    # This video was generated by running the following:
    # ffmpeg -f lavfi -i testsrc=duration=5:size=640x360:rate=25,format=yuv420p -c:v libaom-av1 -crf 30 -colorspace bt709 -color_primaries bt709 -color_trc bt709 av1_video.mkv
    # Note that this video only has 1 stream, at index 0.
    VIDEO_PATH = os.path.join(RESOURCES_DIR, "av1_video.mkv")
    FRAMES = [10]

    for frame in FRAMES:
        frame_name = f"{frame:06d}"
        output_bmp = f"{VIDEO_PATH}.stream0.frame{frame_name}.bmp"
        cmd = [
            "ffmpeg",
            "-y",
            "-i",
            VIDEO_PATH,
            "-vf",
            f"select=eq(n\\,{frame})",
            "-vsync",
            "vfr",
            "-q:v",
            "2",
            output_bmp,
        ]
        subprocess.run(cmd, check=True)
        convert_image_to_tensor(output_bmp)


if __name__ == "__main__":
    main()
